#choose correct probability depending on observed y
right_probs=P[1]^(y==1)*P[2]^(y==2)*P[3]^(y==3)*P[4]^(y==4)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,ncol(X)),rnorm(4)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out = optim(par = c(rep(0,ncol(X)),rnorm(3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out = optim(par = c(rep(0,ncol(X)),rnorm(3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out = optim(par = c(rep(0,ncol(X)),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
llk.ord4 <- function(par, X, y) {
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
#linear predictor (E[y*|x])
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[4]-XB)/(1+exp(tau[4]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
#keep t’s in right order
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
#choose correct probability depending on observed y
right_probs=P[1]^(y==1)*P[2]^(y==2)*P[3]^(y==3)*P[4]^(y==4)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
rnorm(3)
out = optim(par = c(rep(0,4),rnorm(3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
brader <- read.csv("brader.csv")
llk.ord4 <- function(par, X, y) {
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
#linear predictor (E[y*|x])
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[4]-XB)/(1+exp(tau[4]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
#keep t’s in right order
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
#choose correct probability depending on observed y
right_probs=P[1]^(y==1)*P[2]^(y==2)*P[3]^(y==3)*P[4]^(y==4)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,4),rnorm(3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
brader <- read.csv("brader.csv")
llk.ord4 <- function(par, X, y) {
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
#linear predictor (E[y*|x])
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
#keep t’s in right order
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
#choose correct probability depending on observed y
right_probs=P[1]^(y==1)*P[2]^(y==2)*P[3]^(y==3)*P[4]^(y==4)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,4),rnorm(3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
p = ncol(X)
beta=par[1:p]
par = c(rep(0,4),rnorm(3))
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB))
out = optim(par = c(rep(0,4),c(1,2,3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
#linear predictor (E[y*|x])
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
X=as.matrix(brader[,2:5]), y=brader$immigr
X=as.matrix(brader[,2:5])
y=brader$immigr
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
#linear predictor (E[y*|x])
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
right_probs=P[1]^(y==1)*P[2]^(y==2)*P[3]^(y==3)*P[4]^(y==4)
llk.ord4 <- function(par, X, y) {
p = ncol(X)
beta=par[1:p]
tau=par[(p+1):(p+3)]
#linear predictor (E[y*|x])
XB = X%*%beta
P1 = log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P2 = log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P3 = log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P4 = log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
#keep t’s in right order
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
#choose correct probability depending on observed y
right_probs=P[1]^(y==1)*P[2]^(y==2)*P[3]^(y==3)*P[4]^(y==4)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,4),c(1,2,3)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
library(MASS)
plr <- polr(immigr ~ tone+eth+ppage+ppincimp, data = brader)
plr <- polr(as.factor(immigr) ~ tone+eth+ppage+ppincimp, data = brader)
plr
plr <- polr(as.factor(immigr) ~ 0+tone+eth+ppage+ppincimp, data = brader)
plr
plr <- polr(as.factor(immigr) ~ 0+tone+eth+ppage+ppincimp, data = brader,
method = "logistic", Hess = True)
plr <- polr(as.factor(immigr) ~ 0+tone+eth+ppage+ppincimp, data = brader,
method = "logistic", Hess = T)
plr
page(plor)
page(polr)
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "SANN",
control = list(fnscale = -1), hessian = TRUE)
pnorm(0)
dnorm(0)
dim(XB)
(y==1)log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
(y==1)*log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
llk.ord4 <- function(par, X, y) {
p <- ncol(X)
beta <- par[1:p]
tau <- par[(p+1):(p+3)]
P <- X
#linear predictor (E[y*|x])
XB = X%*%beta
P[,1] = (y==1)*log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P[,2] = (y==2)*log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P[,3] = (y==3)*log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P[,4] = (y==4)*log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
#keep t’s in right order
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
#choose correct probability depending on observed y
right_probs=rowsum(P)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "SANN",
control = list(fnscale = -1), hessian = TRUE)
llk.ord4 <- function(par, X, y) {
p <- ncol(X)
beta <- par[1:p]
tau <- par[(p+1):(p+3)]
P <- X
#linear predictor (E[y*|x])
XB = X%*%beta
P[,1] = (y==1)*log(exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P[,2] = (y==2)*log(exp(tau[2]-XB)/(1+exp(tau[2]-XB))-exp(tau[1]-XB)/(1+exp(tau[1]-XB)))
P[,3] = (y==3)*log(exp(tau[3]-XB)/(1+exp(tau[3]-XB))-exp(tau[2]-XB)/(1+exp(tau[2]-XB)))
P[,4] = (y==4)*log(1-exp(tau[3]-XB)/(1+exp(tau[3]-XB)))
#keep t’s in right order
penalty=10^6*(as.numeric(tau[2]>tau[3])+as.numeric(tau[1]>tau[2]))
#choose correct probability depending on observed y
right_probs=rowSums(P)
#final log-likelihood
ll=sum(right_probs)-penalty
return(ll)
}
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "SANN",
control = list(fnscale = -1), hessian = TRUE)
out
out$par
plr
out = optim(par = c(rep(0,4),c(-1,0,1)),
fn = llk.ord4, X=as.matrix(brader[,2:5]), y=brader$immigr,method = "BFGS",
control = list(fnscale = -1), hessian = TRUE)
out
nielsenaid <- read.csv("nielsenaid.csv")
pi
\pi
View(pi)
base::pi
(y[i]-XB)^2/2*sig^2 - log(sqrt(2*base::pi)*sig)
View(nielsenaid)
nielsenaid <- read.csv("nielsenaid.csv")
llk.tbt <- function(par, X, y) {
n <- nrow(X)
p <- ncol(X)
sig <- par[p+1]
#linear predictor (E[y*|x])
XB = X%*%par[1:p]
for (i in 1:n) {
if (y[i] > 0) {
P[i] = (y[i]-XB)^2/2/sig^2 - log(sqrt(2*base::pi)*sig)
} else {
P[i] = log(pnorm(-XB/sig))
}
}
ll=sum(P)
return(ll)
}
out = optim(par = c(rep(0,6),1),
fn = llk.tbt, X=as.matrix(brader[,3:8]), y=nielsenaid$lneconaid, method = "BFGS", control = list(fnscale = -1), hessian = TRUE)
out = optim(par = c(rep(0,6),1),
fn = llk.tbt, X=as.matrix(nielsenaid[,3:8]), y=nielsenaid$lneconaid, method = "BFGS", control = list(fnscale = -1), hessian = TRUE)
llk.tbt <- function(par, X, y) {
n <- nrow(X)
p <- ncol(X)
sig <- par[p+1]
#linear predictor (E[y*|x])
XB = X%*%par[1:p]
P = y
for (i in 1:n) {
if (y[i] > 0) {
P[i] = (y[i]-XB)^2/2/sig^2 - log(sqrt(2*base::pi)*sig)
} else {
P[i] = log(pnorm(-XB/sig))
}
}
ll=sum(P)
return(ll)
}
out = optim(par = c(rep(0,6),1),
fn = llk.tbt, X=as.matrix(nielsenaid[,3:8]), y=nielsenaid$lneconaid, method = "BFGS", control = list(fnscale = -1), hessian = TRUE)
getwd()
data = read.csv(file="/Users/alice/Desktop/responses.csv", header=T)
dat = movie[complete.cases(movie),-c(1,11)]
data = read.csv(file="/Users/alice/Desktop/responses.csv", header=T)
movie = data[, 20:31]
dat = movie[complete.cases(movie),-c(1,11)]
colnames(dat)
colnames(dat)[7] <- "Fantasy"
View(data)
which(colnames(movie)=="Gender")
which(colnames(movie)=="gender")
which(colnames(data)=="gender")
which(colnames(data)=="Gender")
movie = data[, 20:31,145]
dat = movie[complete.cases(movie),-c(1,11)]
colnames(dat)[7] <- "Fantasy"
which(all(dat[,1:10]-dat[,c(2:10,1)]==0))
dat = movie[complete.cases(movie),-c(1,11)]
dat = dat[-which(dat$Gender==""),]
data = read.csv(file="/Users/alice/Desktop/responses.csv", header=T)
movie = data[, 20:31,145]
dat = movie[complete.cases(movie),-c(1,11)]
dat = dat[-which(dat$Gender==""),]
data = read.csv(file="/Users/alice/Desktop/responses.csv", header=T)
movie = data[, c(20:31,145)]
dat = movie[complete.cases(movie),-c(1,11)]
dat = dat[-which(dat$Gender==""),]
colnames(dat)[7] <- "Fantasy"
check = apply(dat[,1:10], 1, function(tl) length(table(tl)))
fake = which(as.numeric(check)==1)
dat = dat[-fake,]
save(dat, file = "data.RData")
load(data.RData)
load("data.RData")
describe(dat)
library(psych)
library(homals)
# data summary
describe(dat)
as.numeric(dat[,"Gender"])-1
as.numeric(dat[,"Gender"])-2
dat[,13] = as.numeric(dat[,"Gender"])-2
length(as.numeric(dat[,"Gender"])-2)
dat[,"Gender"] = as.numeric(dat[,"Gender"])-2
save(dat, file = "data.RData")
load("data.RData")
des = describe(dat)
knitr::kable(des)
dat
dat[,"Gender"] = as.numeric(dat[,"Gender"])-2
dat
save(dat, file = "data.RData")
getwd()
## Delete dubious observation
# check = apply(dat[,1:10], 1, function(tl) length(table(tl)))
# fake = which(as.numeric(check)==1)
# dat = dat[-fake,]
# save(dat, file = "data.RData")
## Load data and packages
load("data.RData")
# data summary
library(psych)
des = describe(dat)
knitr::kable(des)
## Delete dubious observation
# check = apply(dat[,1:10], 1, function(tl) length(table(tl)))
# fake = which(as.numeric(check)==1)
# dat = dat[-fake,]
# save(dat, file = "data.RData")
## Load data and packages
load("data.RData")
# data summary
library(psych)
des = describe(dat)
knitr::kable(des)
dat[,"Gender"] = as.numeric(dat[,"Gender"])-2
save(dat, file = "data.RData")
load("data.RData")
dat
## Delete dubious observation
# check = apply(dat[,1:10], 1, function(tl) length(table(tl)))
# fake = which(as.numeric(check)==1)
# dat = dat[-fake,]
# save(dat, file = "data.RData")
## Load data and packages
load("data.RData")
## Delete dubious observation
# check = apply(dat[,1:10], 1, function(tl) length(table(tl)))
# fake = which(as.numeric(check)==1)
# dat = dat[-fake,]
# save(dat, file = "data.RData")
## Load data and packages
load("data.RData")
# data summary
library(psych)
des = describe(dat)
knitr::kable(des)
## Delete dubious observation
# check = apply(dat[,1:10], 1, function(tl) length(table(tl)))
# fake = which(as.numeric(check)==1)
# dat = dat[-fake,]
# save(dat, file = "data.RData")
## Load data and packages
load("data.RData")
# data summary
library(psych)
des = describe(dat)
knitr::kable(des[,c("min", "max", "mean", "median", "skew", "kurtosis")])
load("data.RData")
features = dat[1:10]
## Pearson Correlation
pear_cor = cor(features)
cor.plot(pear_cor, numbers=T, upper=FALSE, main = "Pearson Correlation", show.legend = FALSE)
## Polychoric correlation
poly_cor = polychoric(features)
cor.plot(poly_cor$rho, numbers=T, upper=FALSE, main = "Polychoric Correlation", show.legend = FALSE)
load("data.RData")
features = dat[1:10]
## Pearson Correlation
pear_cor = cor(features)
cor.plot(pear_cor, numbers=T, upper=FALSE, main = "Pearson Correlation", show.legend = FALSE)
## Polychoric correlation
poly_cor = polychoric(features)
cor.plot(poly_cor$rho, numbers=T, upper=FALSE, main = "Polychoric Correlation", show.legend = FALSE)
poly_cor
poly_cor$tau
### Plot the difference
diff = (poly_cor$rho - poly_cor)*((poly_cor>=0)*2-1)
load("data.RData")
features = dat[1:10]
## Pearson Correlation
pear_cor = cor(features)
cor.plot(pear_cor, numbers=T, upper=FALSE, main = "Pearson Correlation", show.legend = FALSE)
## Polychoric correlation
poly_cor = polychoric(features)
### Thresholds/Scaling results
poly_cor$tau
cor.plot(poly_cor$rho, numbers=T, upper=FALSE, main = "Polychoric Correlation", show.legend = FALSE)
### Plot the difference
diff = (poly_cor$rho - pear_cor)*((pear_cor>=0)*2-1)
diff[3,2] = 0.02
diff[9,3] =0.02
cor.plot(diff, numbers=T, upper=FALSE, diag=FALSE)
fa.parallel(r$rho, fm="pa", fa="fa")
load("/Users/alice/Downloads/data.RData")
load("data.RData")
load("data.RData")
load("data.RData")
install.packages("haven")
a = "I am using HackerRank to improve programming"
a
a[1]
words_s = strsplit(a, " ")
words_s
words_s[[1]]
words_s[[1]] - "I"
t = "am HackerRank to improve"
words_t = strsplit(t, " ")
words_t
words_s[[1]] - words_t[[1]]
setdiff(words_s[[1]], words_t[[1]])
words_s[[1]][words_s[[1]] %nin% words_t[[1]]]
words_s[[1]][words_s[[1]] %in% words_t[[1]]]
words_s[[1]][!words_s[[1]] %in% words_t[[1]]]
!words_s[[1]] %in% words_t[[1]]
s = words_s[[1]]
t = words_t[[1]]
s
t
which(s %in)
which(s %in% t)
pos = which(s %in% t)
pos
pos = c(2,4,6,5)
pos
diff(pos)
diff(pos)>0
all(diff(pos) > 0)
words_s[[1]][!pos]
s[!pos]
s[pos]
s[-pos]
pos
diff(pos)>0
d = c(1,1,1,0,1,1,0,1)
d
for (i in d) {}
a = "I am using HackerRank to improve programming"
a
strsplit(a, " ")[[1]]
s
for (word in s) {
print(word)
}
s[1]==t[1]
t
t[-1]
cat("TITLE extra line", "2 3 5 7", "", "11 13 17", file = "ex.data",
sep = "\n")
readLines("ex.data", n = -1)
unlink("ex.data") # tidy up
cat("TITLE extra line", "2 3 5 7", "", "11 13 17", file = "ex.data",
sep = "\n")
readLines("ex.data", n = 1)
unlink("ex.data") # tidy up
readLines("ex.data", n = 1)
cat("TITLE extra line", "2 3 5 7", "", "11 13 17", file = "ex.data",
sep = "\n")
readLines("ex.data", n = 1)
unlink("ex.data") # tidy up
cat("TITLE extra line", "2 3 5 7", "", "11 13 17", file = "ex.data",
sep = "\n")
readLines("ex.data", n = -1)
unlink("ex.data") # tidy up
cat("TITLE extra line", "2 3 5 7", "", "11 13 17", file = "ex.data",
sep = "\n")
r = readLines("ex.data", n = -1)
unlink("ex.data") # tidy up
r
r[2]
as.integer(strsplit(r[2], "")[[1]])
as.integer(strsplit(r[2], " ")[[1]])
r[3:]
r[3::]
r[3:length(r)]
as.integer(strsplit(r[2], " ")[[1]])
i = as.integer(strsplit(r[2], " ")[[1]])
i
i[1]
i[2]
c(1,2,3)-c(3,2,1)
sum(c(1,2,3)-c(3,2,1))
pnorm(1, 0.7, 0.3)
dnorm(1, 0.7, 0.3)
